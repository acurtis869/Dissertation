{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic NMT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMitnMqr6OAlMWha415ZdOJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acurtis869/Dissertation/blob/main/Basic_NMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNa5MTgIeyoD"
      },
      "source": [
        "Check what GPU we are running on:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWtO8bE5fAwJ",
        "outputId": "d67b4d03-6f48-4bf9-f269-53c04a019780"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun 20 11:56:21 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dbXqHRifHep"
      },
      "source": [
        "Import TensorFlow and check it is using GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsItH28GfSah",
        "outputId": "5bd74ae6-fc79-429f-9555-fcd28f2260e9"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.test.gpu_device_name())\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n",
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrLlHfEpfbK3"
      },
      "source": [
        "Install Open NMT to remote machine:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vEmiTYQRfphA",
        "outputId": "c77d0cab-5272-4316-fd3f-b886bc3c31e9"
      },
      "source": [
        "!pip install OpenNMT-tf[tensorflow]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting OpenNMT-tf[tensorflow]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/e1/6fc1b73a32014593536e04e3ab787c6acff04bf5e5cc51eeed0e0b0b263a/OpenNMT_tf-2.20.0-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 1.6MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons<0.14,>=0.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 15.8MB/s \n",
            "\u001b[?25hCollecting pyyaml<5.5,>=5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 19.0MB/s \n",
            "\u001b[?25hCollecting sacrebleu<1.6,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n",
            "\u001b[?25hCollecting ctranslate2<3,>=2.0.0; platform_system == \"Linux\" or platform_system == \"Darwin\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/7b/683ffc38bd3bd64a6e9cb97a36c7c0de957fa6b2860dd15b9f6196a4fd11/ctranslate2-2.1.0-cp37-cp37m-manylinux2014_x86_64.whl (22.0MB)\n",
            "\u001b[K     |████████████████████████████████| 22.0MB 10.2MB/s \n",
            "\u001b[?25hCollecting pyonmttok<2,>=1.26.2; platform_system == \"Linux\" or platform_system == \"Darwin\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/0c/bad1d4c1c42885f89ef7e9697534af17906e59fc6703872b2a3a52d7c06f/pyonmttok-1.26.2-cp37-cp37m-manylinux1_x86_64.whl (14.3MB)\n",
            "\u001b[K     |████████████████████████████████| 14.3MB 17.7MB/s \n",
            "\u001b[?25hCollecting rouge<2,>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\" in /usr/local/lib/python3.7/dist-packages (from OpenNMT-tf[tensorflow]) (2.5.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons<0.14,>=0.13->OpenNMT-tf[tensorflow]) (2.7.1)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ctranslate2<3,>=2.0.0; platform_system == \"Linux\" or platform_system == \"Darwin\"->OpenNMT-tf[tensorflow]) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge<2,>=1.0->OpenNMT-tf[tensorflow]) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (3.7.4.3)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (3.12.4)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (1.34.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (0.12.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (1.1.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (2.5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (57.0.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (1.31.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (0.4.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (0.2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (4.5.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6.0,>=2.3.0; extra == \"tensorflow\"->OpenNMT-tf[tensorflow]) (3.1.1)\n",
            "Installing collected packages: tensorflow-addons, pyyaml, portalocker, sacrebleu, ctranslate2, pyonmttok, rouge, OpenNMT-tf\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed OpenNMT-tf-2.20.0 ctranslate2-2.1.0 portalocker-2.0.0 pyonmttok-1.26.2 pyyaml-5.4.1 rouge-1.0.0 sacrebleu-1.5.1 tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6KktVZGftPW"
      },
      "source": [
        "Upload data and config. files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUFyrA31f1Ou"
      },
      "source": [
        "import yaml\n",
        "!mkdir Europarl\n",
        "!cd Europarl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFwYvq0CQo8R"
      },
      "source": [
        "Build vocabularies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5urUQYWQjpo",
        "outputId": "17eed929-93e2-4a3a-f960-b4ab423b68a9"
      },
      "source": [
        "!onmt-build-vocab --size 50000 --save_vocab Europarl/fre_vocab.txt Europarl/fre_train.txt\n",
        "!onmt-build-vocab --size 50000 --save_vocab Europarl/eng_vocab.txt Europarl/eng_train.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-20 11:58:42.886415: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-20 11:58:44.385353: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-06-20 11:58:44.390124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:44.391036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-06-20 11:58:44.391082: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-20 11:58:44.394209: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-06-20 11:58:44.394280: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-06-20 11:58:44.395986: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-20 11:58:44.396352: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-20 11:58:44.398397: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-20 11:58:44.399018: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-06-20 11:58:44.399220: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-06-20 11:58:44.399326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:44.400245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:44.401179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-06-20 11:58:44.401748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:44.402654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-06-20 11:58:44.402758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:44.403666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:44.404529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-06-20 11:58:44.404590: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-20 11:58:45.010724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-20 11:58:45.010795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-06-20 11:58:45.010828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-06-20 11:58:45.011021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:45.011985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:45.012882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:45.013732: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-06-20 11:58:45.013799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15088 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2021-06-20 11:58:50.332732: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-20 11:58:51.861116: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-06-20 11:58:51.865868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:51.866820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-06-20 11:58:51.866867: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-20 11:58:51.869741: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-06-20 11:58:51.869852: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-06-20 11:58:51.871612: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-20 11:58:51.872008: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-20 11:58:51.873898: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-20 11:58:51.874560: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-06-20 11:58:51.874762: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-06-20 11:58:51.874876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:51.875824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:51.876703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-06-20 11:58:51.877289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:51.878144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-06-20 11:58:51.878241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:51.879164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:51.880015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-06-20 11:58:51.880075: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-20 11:58:52.496020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-20 11:58:52.496103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-06-20 11:58:52.496142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-06-20 11:58:52.496335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:52.497326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:52.498212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:58:52.499083: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-06-20 11:58:52.499166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15088 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxeezOdQR0RJ"
      },
      "source": [
        "Start training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWqwtyVXSBnB",
        "outputId": "bb9162b1-b4d5-4b95-a20f-634048e6a115"
      },
      "source": [
        "!onmt-main --model_type Transformer --config Europarl/config.yml --auto_config train --with_eval "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-20 11:59:04.003187: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-20 11:59:05.548670: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-06-20 11:59:05.553404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:59:05.554276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-06-20 11:59:05.554322: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-20 11:59:05.561540: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-06-20 11:59:05.561611: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-06-20 11:59:05.563372: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-20 11:59:05.566063: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-20 11:59:05.567862: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-20 11:59:05.575118: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-06-20 11:59:05.575375: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-06-20 11:59:05.575499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:59:05.576495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:59:05.577366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-06-20 11:59:05.580000: I onmt-main:8] Creating model directory run/\n",
            "2021-06-20 11:59:05.719000: I main.py:318] Using OpenNMT-tf version 2.20.0\n",
            "2021-06-20 11:59:05.720000: I main.py:318] Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "2021-06-20 11:59:05.724048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:59:05.724995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-06-20 11:59:05.725119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:59:05.725976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:59:05.726851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-06-20 11:59:05.726981: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-20 11:59:06.362673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-20 11:59:06.362728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-06-20 11:59:06.362749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-06-20 11:59:06.362944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:59:06.363881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:59:06.364822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 11:59:06.365684: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-06-20 11:59:06.365744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15088 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2021-06-20 11:59:06.370000: I main.py:326] Using parameters:\n",
            "data:\n",
            "  eval_features_file: Europarl/fre_val.txt\n",
            "  eval_labels_file: Europarl/eng_val.txt\n",
            "  source_vocabulary: Europarl/fre_vocab.txt\n",
            "  target_vocabulary: Europarl/eng_vocab.txt\n",
            "  train_features_file: Europarl/fre_train.txt\n",
            "  train_labels_file: Europarl/eng_train.txt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  early_stopping:\n",
            "    metric: loss\n",
            "    min_improvement: 0.05\n",
            "    steps: 4\n",
            "  length_bucket_width: 5\n",
            "  save_eval_predictions: true\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: run/\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 2.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: LazyAdam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.9\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 1\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 100\n",
            "  maximum_labels_length: 100\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "2021-06-20 11:59:06.873000: W runner.py:242] No checkpoint to restore in run/\n",
            "2021-06-20 11:59:06.888000: W deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/summary/summary_iterator.py:31: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "2021-06-20 11:59:08.699000: I main.py:326] Accumulate gradients of 9 iterations to reach effective batch size of 25000\n",
            "2021-06-20 11:59:08.750000: I dataset_ops.py:2120] Training on 100000 examples\n",
            "2021-06-20 11:59:09.712927: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-06-20 11:59:09.716112: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2299995000 Hz\n",
            "2021-06-20 11:59:29.367000: I control_flow.py:1225] Number of model parameters: 101781835\n",
            "2021-06-20 11:59:30.202000: I control_flow.py:1225] Number of model weights: 260 (trainable = 260, non trainable = 0)\n",
            "2021-06-20 11:59:52.661383: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-06-20 11:59:53.714302: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8004\n",
            "2021-06-20 11:59:53.913007: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-06-20 11:59:55.077913: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-06-20 12:00:07.260000: I training.py:186] Saved checkpoint run/ckpt-1\n",
            "2021-06-20 12:03:45.864000: I runner.py:281] Step = 100 ; steps/s = 0.45, source words/s = 11314, target words/s = 11275 ; Learning rate = 0.000012 ; Loss = 9.706094\n",
            "2021-06-20 12:07:28.094000: I runner.py:281] Step = 200 ; steps/s = 0.45, source words/s = 11284, target words/s = 11244 ; Learning rate = 0.000025 ; Loss = 8.552644\n",
            "2021-06-20 12:11:08.352000: I runner.py:281] Step = 300 ; steps/s = 0.45, source words/s = 11304, target words/s = 11251 ; Learning rate = 0.000037 ; Loss = 7.440518\n",
            "2021-06-20 12:14:45.751000: I runner.py:281] Step = 400 ; steps/s = 0.46, source words/s = 11285, target words/s = 11239 ; Learning rate = 0.000050 ; Loss = 6.973201\n",
            "2021-06-20 12:18:22.566000: I runner.py:281] Step = 500 ; steps/s = 0.46, source words/s = 11312, target words/s = 11268 ; Learning rate = 0.000062 ; Loss = 6.646794\n",
            "2021-06-20 12:21:59.102000: I runner.py:281] Step = 600 ; steps/s = 0.46, source words/s = 11332, target words/s = 11283 ; Learning rate = 0.000074 ; Loss = 6.354728\n",
            "2021-06-20 12:25:35.701000: I runner.py:281] Step = 700 ; steps/s = 0.46, source words/s = 11324, target words/s = 11281 ; Learning rate = 0.000087 ; Loss = 6.146773\n",
            "2021-06-20 12:29:12.164000: I runner.py:281] Step = 800 ; steps/s = 0.46, source words/s = 11332, target words/s = 11287 ; Learning rate = 0.000099 ; Loss = 5.945372\n",
            "2021-06-20 12:32:48.606000: I runner.py:281] Step = 900 ; steps/s = 0.46, source words/s = 11333, target words/s = 11291 ; Learning rate = 0.000111 ; Loss = 5.791600\n",
            "2021-06-20 12:36:25.025000: I runner.py:281] Step = 1000 ; steps/s = 0.46, source words/s = 11331, target words/s = 11290 ; Learning rate = 0.000124 ; Loss = 5.599657\n",
            "2021-06-20 12:36:29.954000: I training.py:186] Saved checkpoint run/ckpt-1000\n",
            "2021-06-20 12:40:06.444000: I runner.py:281] Step = 1100 ; steps/s = 0.46, source words/s = 11335, target words/s = 11281 ; Learning rate = 0.000136 ; Loss = 5.521701\n",
            "2021-06-20 12:43:42.799000: I runner.py:281] Step = 1200 ; steps/s = 0.46, source words/s = 11337, target words/s = 11298 ; Learning rate = 0.000148 ; Loss = 5.170148\n",
            "2021-06-20 12:47:19.212000: I runner.py:281] Step = 1300 ; steps/s = 0.46, source words/s = 11337, target words/s = 11287 ; Learning rate = 0.000161 ; Loss = 4.783025\n",
            "2021-06-20 12:50:56.050000: I runner.py:281] Step = 1400 ; steps/s = 0.46, source words/s = 11314, target words/s = 11264 ; Learning rate = 0.000173 ; Loss = 4.624055\n",
            "2021-06-20 12:54:32.723000: I runner.py:281] Step = 1500 ; steps/s = 0.46, source words/s = 11320, target words/s = 11280 ; Learning rate = 0.000185 ; Loss = 4.316732\n",
            "2021-06-20 12:58:09.165000: I runner.py:281] Step = 1600 ; steps/s = 0.46, source words/s = 11337, target words/s = 11288 ; Learning rate = 0.000198 ; Loss = 3.980251\n",
            "2021-06-20 13:01:45.590000: I runner.py:281] Step = 1700 ; steps/s = 0.46, source words/s = 11336, target words/s = 11283 ; Learning rate = 0.000210 ; Loss = 3.870262\n",
            "2021-06-20 13:05:22.772000: I runner.py:281] Step = 1800 ; steps/s = 0.46, source words/s = 11295, target words/s = 11251 ; Learning rate = 0.000222 ; Loss = 3.838000\n",
            "2021-06-20 13:08:59.757000: I runner.py:281] Step = 1900 ; steps/s = 0.46, source words/s = 11302, target words/s = 11262 ; Learning rate = 0.000235 ; Loss = 3.588217\n",
            "2021-06-20 13:12:36.628000: I runner.py:281] Step = 2000 ; steps/s = 0.46, source words/s = 11311, target words/s = 11265 ; Learning rate = 0.000247 ; Loss = 3.449523\n",
            "2021-06-20 13:12:41.597000: I training.py:186] Saved checkpoint run/ckpt-2000\n",
            "2021-06-20 13:16:18.900000: I runner.py:281] Step = 2100 ; steps/s = 0.46, source words/s = 11288, target words/s = 11241 ; Learning rate = 0.000260 ; Loss = 3.354817\n",
            "2021-06-20 13:19:55.381000: I runner.py:281] Step = 2200 ; steps/s = 0.46, source words/s = 11331, target words/s = 11287 ; Learning rate = 0.000272 ; Loss = 3.361990\n",
            "2021-06-20 13:23:32.628000: I runner.py:281] Step = 2300 ; steps/s = 0.46, source words/s = 11293, target words/s = 11248 ; Learning rate = 0.000284 ; Loss = 3.222278\n",
            "2021-06-20 13:27:10.384000: I runner.py:281] Step = 2400 ; steps/s = 0.46, source words/s = 11265, target words/s = 11218 ; Learning rate = 0.000297 ; Loss = 3.194977\n",
            "2021-06-20 13:30:47.368000: I runner.py:281] Step = 2500 ; steps/s = 0.46, source words/s = 11304, target words/s = 11259 ; Learning rate = 0.000309 ; Loss = 3.080323\n",
            "2021-06-20 13:34:23.837000: I runner.py:281] Step = 2600 ; steps/s = 0.46, source words/s = 11332, target words/s = 11286 ; Learning rate = 0.000321 ; Loss = 3.346585\n",
            "2021-06-20 13:38:03.463000: I runner.py:281] Step = 2700 ; steps/s = 0.46, source words/s = 11372, target words/s = 11333 ; Learning rate = 0.000334 ; Loss = 3.119869\n",
            "2021-06-20 13:41:44.179000: I runner.py:281] Step = 2800 ; steps/s = 0.45, source words/s = 11364, target words/s = 11321 ; Learning rate = 0.000346 ; Loss = 2.893858\n",
            "2021-06-20 13:45:23.045000: I runner.py:281] Step = 2900 ; steps/s = 0.46, source words/s = 11376, target words/s = 11320 ; Learning rate = 0.000358 ; Loss = 2.836073\n",
            "2021-06-20 13:48:59.203000: I runner.py:281] Step = 3000 ; steps/s = 0.46, source words/s = 11351, target words/s = 11301 ; Learning rate = 0.000371 ; Loss = 2.742160\n",
            "2021-06-20 13:49:04.047000: I training.py:186] Saved checkpoint run/ckpt-3000\n",
            "2021-06-20 13:52:40.713000: I runner.py:281] Step = 3100 ; steps/s = 0.46, source words/s = 11321, target words/s = 11280 ; Learning rate = 0.000383 ; Loss = 2.708059\n",
            "2021-06-20 13:56:17.313000: I runner.py:281] Step = 3200 ; steps/s = 0.46, source words/s = 11322, target words/s = 11280 ; Learning rate = 0.000395 ; Loss = 2.657462\n",
            "2021-06-20 13:59:53.604000: I runner.py:281] Step = 3300 ; steps/s = 0.46, source words/s = 11343, target words/s = 11293 ; Learning rate = 0.000408 ; Loss = 2.585667\n",
            "2021-06-20 14:03:29.790000: I runner.py:281] Step = 3400 ; steps/s = 0.46, source words/s = 11346, target words/s = 11305 ; Learning rate = 0.000420 ; Loss = 2.497614\n",
            "2021-06-20 14:07:05.941000: I runner.py:281] Step = 3500 ; steps/s = 0.46, source words/s = 11348, target words/s = 11299 ; Learning rate = 0.000432 ; Loss = 2.491011\n",
            "2021-06-20 14:10:41.985000: I runner.py:281] Step = 3600 ; steps/s = 0.46, source words/s = 11354, target words/s = 11313 ; Learning rate = 0.000445 ; Loss = 2.437321\n",
            "2021-06-20 14:14:18.126000: I runner.py:281] Step = 3700 ; steps/s = 0.46, source words/s = 11351, target words/s = 11300 ; Learning rate = 0.000457 ; Loss = 2.369096\n",
            "2021-06-20 14:17:54.295000: I runner.py:281] Step = 3800 ; steps/s = 0.46, source words/s = 11346, target words/s = 11303 ; Learning rate = 0.000470 ; Loss = 2.321004\n",
            "2021-06-20 14:21:30.670000: I runner.py:281] Step = 3900 ; steps/s = 0.46, source words/s = 11339, target words/s = 11292 ; Learning rate = 0.000482 ; Loss = 2.281831\n",
            "2021-06-20 14:25:06.762000: I runner.py:281] Step = 4000 ; steps/s = 0.46, source words/s = 11353, target words/s = 11308 ; Learning rate = 0.000494 ; Loss = 2.234777\n",
            "2021-06-20 14:25:12.618000: I training.py:186] Saved checkpoint run/ckpt-4000\n",
            "2021-06-20 14:28:48.838000: I runner.py:281] Step = 4100 ; steps/s = 0.46, source words/s = 11345, target words/s = 11299 ; Learning rate = 0.000507 ; Loss = 2.198014\n",
            "2021-06-20 14:32:24.989000: I runner.py:281] Step = 4200 ; steps/s = 0.46, source words/s = 11351, target words/s = 11302 ; Learning rate = 0.000519 ; Loss = 2.174810\n",
            "2021-06-20 14:36:01.339000: I runner.py:281] Step = 4300 ; steps/s = 0.46, source words/s = 11337, target words/s = 11296 ; Learning rate = 0.000531 ; Loss = 2.130217\n",
            "2021-06-20 14:39:37.540000: I runner.py:281] Step = 4400 ; steps/s = 0.46, source words/s = 11347, target words/s = 11299 ; Learning rate = 0.000544 ; Loss = 2.111929\n",
            "2021-06-20 14:43:13.702000: I runner.py:281] Step = 4500 ; steps/s = 0.46, source words/s = 11346, target words/s = 11304 ; Learning rate = 0.000556 ; Loss = 2.100361\n",
            "2021-06-20 14:46:50.080000: I runner.py:281] Step = 4600 ; steps/s = 0.46, source words/s = 11336, target words/s = 11290 ; Learning rate = 0.000568 ; Loss = 2.065380\n",
            "2021-06-20 14:50:26.407000: I runner.py:281] Step = 4700 ; steps/s = 0.46, source words/s = 11339, target words/s = 11293 ; Learning rate = 0.000581 ; Loss = 2.036716\n",
            "2021-06-20 14:54:02.628000: I runner.py:281] Step = 4800 ; steps/s = 0.46, source words/s = 11346, target words/s = 11297 ; Learning rate = 0.000593 ; Loss = 2.015945\n",
            "2021-06-20 14:57:38.768000: I runner.py:281] Step = 4900 ; steps/s = 0.46, source words/s = 11348, target words/s = 11306 ; Learning rate = 0.000605 ; Loss = 2.013931\n",
            "2021-06-20 15:01:14.820000: I runner.py:281] Step = 5000 ; steps/s = 0.46, source words/s = 11354, target words/s = 11307 ; Learning rate = 0.000618 ; Loss = 2.025360\n",
            "2021-06-20 15:01:19.743000: I training.py:186] Saved checkpoint run/ckpt-5000\n",
            "2021-06-20 15:01:19.743000: I training.py:202] Running evaluation for step 5000\n",
            "2021-06-20 15:01:28.753000: W deprecation.py:534] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "2021-06-20 15:01:32.649076: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.649284: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.652161: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.654063: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.655981: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.657852: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.659730: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.667434: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.689430: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.691260: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.692118: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.696184: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.697449: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.699123: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.702813: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.703857: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.704859: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.708392: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.709381: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.710331: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.716497: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.717562: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.718569: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:01:32.722564: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 15:03:41.784000: I training.py:202] Evaluation predictions saved to run/eval/predictions.txt.5000\n",
            "2021-06-20 15:03:41.784000: I training.py:202] Evaluation result for step 5000: loss = 3.068723 ; perplexity = 21.514404\n",
            "2021-06-20 15:07:18.542000: I runner.py:281] Step = 5100 ; steps/s = 0.46, source words/s = 11317, target words/s = 11273 ; Learning rate = 0.000630 ; Loss = 2.002229\n",
            "2021-06-20 15:10:55.405000: I runner.py:281] Step = 5200 ; steps/s = 0.46, source words/s = 11311, target words/s = 11265 ; Learning rate = 0.000642 ; Loss = 1.918450\n",
            "2021-06-20 15:14:35.397000: I runner.py:281] Step = 5300 ; steps/s = 0.45, source words/s = 11352, target words/s = 11315 ; Learning rate = 0.000655 ; Loss = 1.962512\n",
            "2021-06-20 15:18:16.668000: I runner.py:281] Step = 5400 ; steps/s = 0.45, source words/s = 11335, target words/s = 11293 ; Learning rate = 0.000667 ; Loss = 1.956327\n",
            "2021-06-20 15:21:56.152000: I runner.py:281] Step = 5500 ; steps/s = 0.46, source words/s = 11346, target words/s = 11288 ; Learning rate = 0.000680 ; Loss = 1.885195\n",
            "2021-06-20 15:25:32.694000: I runner.py:281] Step = 5600 ; steps/s = 0.46, source words/s = 11331, target words/s = 11282 ; Learning rate = 0.000692 ; Loss = 1.881968\n",
            "2021-06-20 15:29:09.098000: I runner.py:281] Step = 5700 ; steps/s = 0.46, source words/s = 11334, target words/s = 11291 ; Learning rate = 0.000704 ; Loss = 1.861134\n",
            "2021-06-20 15:32:45.451000: I runner.py:281] Step = 5800 ; steps/s = 0.46, source words/s = 11339, target words/s = 11291 ; Learning rate = 0.000717 ; Loss = 1.827962\n",
            "2021-06-20 15:36:21.848000: I runner.py:281] Step = 5900 ; steps/s = 0.46, source words/s = 11336, target words/s = 11291 ; Learning rate = 0.000729 ; Loss = 1.827009\n",
            "2021-06-20 15:39:58.086000: I runner.py:281] Step = 6000 ; steps/s = 0.46, source words/s = 11341, target words/s = 11302 ; Learning rate = 0.000741 ; Loss = 1.800850\n",
            "2021-06-20 15:40:03.792000: I training.py:186] Saved checkpoint run/ckpt-6000\n",
            "2021-06-20 15:43:40.196000: I runner.py:281] Step = 6100 ; steps/s = 0.46, source words/s = 11332, target words/s = 11289 ; Learning rate = 0.000754 ; Loss = 1.790438\n",
            "2021-06-20 15:47:16.820000: I runner.py:281] Step = 6200 ; steps/s = 0.46, source words/s = 11329, target words/s = 11278 ; Learning rate = 0.000766 ; Loss = 1.784250\n",
            "2021-06-20 15:50:53.497000: I runner.py:281] Step = 6300 ; steps/s = 0.46, source words/s = 11316, target words/s = 11275 ; Learning rate = 0.000778 ; Loss = 1.837348\n",
            "2021-06-20 15:54:29.917000: I runner.py:281] Step = 6400 ; steps/s = 0.46, source words/s = 11333, target words/s = 11291 ; Learning rate = 0.000791 ; Loss = 1.795630\n",
            "2021-06-20 15:58:06.401000: I runner.py:281] Step = 6500 ; steps/s = 0.46, source words/s = 11334, target words/s = 11287 ; Learning rate = 0.000803 ; Loss = 1.752784\n",
            "2021-06-20 16:01:43.050000: I runner.py:281] Step = 6600 ; steps/s = 0.46, source words/s = 11326, target words/s = 11276 ; Learning rate = 0.000815 ; Loss = 1.737303\n",
            "2021-06-20 16:05:19.609000: I runner.py:281] Step = 6700 ; steps/s = 0.46, source words/s = 11326, target words/s = 11278 ; Learning rate = 0.000828 ; Loss = 1.740184\n",
            "2021-06-20 16:08:55.984000: I runner.py:281] Step = 6800 ; steps/s = 0.46, source words/s = 11343, target words/s = 11294 ; Learning rate = 0.000840 ; Loss = 1.732021\n",
            "2021-06-20 16:12:32.555000: I runner.py:281] Step = 6900 ; steps/s = 0.46, source words/s = 11322, target words/s = 11282 ; Learning rate = 0.000852 ; Loss = 1.708815\n",
            "2021-06-20 16:16:09.109000: I runner.py:281] Step = 7000 ; steps/s = 0.46, source words/s = 11328, target words/s = 11284 ; Learning rate = 0.000865 ; Loss = 1.734419\n",
            "2021-06-20 16:16:14.942000: I training.py:186] Saved checkpoint run/ckpt-7000\n",
            "2021-06-20 16:19:51.753000: I runner.py:281] Step = 7100 ; steps/s = 0.46, source words/s = 11310, target words/s = 11268 ; Learning rate = 0.000877 ; Loss = 1.730469\n",
            "2021-06-20 16:23:28.982000: I runner.py:281] Step = 7200 ; steps/s = 0.46, source words/s = 11298, target words/s = 11247 ; Learning rate = 0.000890 ; Loss = 1.725648\n",
            "2021-06-20 16:27:06.713000: I runner.py:281] Step = 7300 ; steps/s = 0.46, source words/s = 11264, target words/s = 11221 ; Learning rate = 0.000902 ; Loss = 1.717269\n",
            "2021-06-20 16:30:44.562000: I runner.py:281] Step = 7400 ; steps/s = 0.46, source words/s = 11260, target words/s = 11216 ; Learning rate = 0.000914 ; Loss = 1.729202\n",
            "2021-06-20 16:34:22.348000: I runner.py:281] Step = 7500 ; steps/s = 0.46, source words/s = 11261, target words/s = 11218 ; Learning rate = 0.000927 ; Loss = 1.724371\n",
            "2021-06-20 16:38:00.429000: I runner.py:281] Step = 7600 ; steps/s = 0.46, source words/s = 11250, target words/s = 11203 ; Learning rate = 0.000939 ; Loss = 1.725560\n",
            "2021-06-20 16:41:38.448000: I runner.py:281] Step = 7700 ; steps/s = 0.46, source words/s = 11252, target words/s = 11207 ; Learning rate = 0.000951 ; Loss = 1.737623\n",
            "2021-06-20 16:45:16.546000: I runner.py:281] Step = 7800 ; steps/s = 0.46, source words/s = 11248, target words/s = 11201 ; Learning rate = 0.000964 ; Loss = 1.721054\n",
            "2021-06-20 16:48:57.759000: I runner.py:281] Step = 7900 ; steps/s = 0.45, source words/s = 11290, target words/s = 11251 ; Learning rate = 0.000976 ; Loss = 1.707079\n",
            "2021-06-20 16:52:40.119000: I runner.py:281] Step = 8000 ; steps/s = 0.45, source words/s = 11278, target words/s = 11238 ; Learning rate = 0.000988 ; Loss = 1.682855\n",
            "2021-06-20 16:52:45.919000: I training.py:186] Saved checkpoint run/ckpt-8000\n",
            "2021-06-20 16:56:26.762000: I runner.py:281] Step = 8100 ; steps/s = 0.45, source words/s = 11277, target words/s = 11220 ; Learning rate = 0.000982 ; Loss = 1.679615\n",
            "2021-06-20 17:00:04.715000: I runner.py:281] Step = 8200 ; steps/s = 0.46, source words/s = 11253, target words/s = 11213 ; Learning rate = 0.000976 ; Loss = 1.646623\n",
            "2021-06-20 17:03:42.626000: I runner.py:281] Step = 8300 ; steps/s = 0.46, source words/s = 11258, target words/s = 11209 ; Learning rate = 0.000970 ; Loss = 1.649537\n",
            "2021-06-20 17:07:20.643000: I runner.py:281] Step = 8400 ; steps/s = 0.46, source words/s = 11250, target words/s = 11207 ; Learning rate = 0.000964 ; Loss = 1.644509\n",
            "2021-06-20 17:10:58.241000: I runner.py:281] Step = 8500 ; steps/s = 0.46, source words/s = 11275, target words/s = 11227 ; Learning rate = 0.000959 ; Loss = 1.637429\n",
            "2021-06-20 17:14:35.769000: I runner.py:281] Step = 8600 ; steps/s = 0.46, source words/s = 11276, target words/s = 11232 ; Learning rate = 0.000953 ; Loss = 1.637901\n",
            "2021-06-20 17:18:13.300000: I runner.py:281] Step = 8700 ; steps/s = 0.46, source words/s = 11277, target words/s = 11231 ; Learning rate = 0.000948 ; Loss = 1.614138\n",
            "2021-06-20 17:21:51.027000: I runner.py:281] Step = 8800 ; steps/s = 0.46, source words/s = 11265, target words/s = 11223 ; Learning rate = 0.000942 ; Loss = 1.620071\n",
            "2021-06-20 17:25:28.546000: I runner.py:281] Step = 8900 ; steps/s = 0.46, source words/s = 11279, target words/s = 11232 ; Learning rate = 0.000937 ; Loss = 1.615836\n",
            "2021-06-20 17:29:06.103000: I runner.py:281] Step = 9000 ; steps/s = 0.46, source words/s = 11274, target words/s = 11230 ; Learning rate = 0.000932 ; Loss = 1.609319\n",
            "2021-06-20 17:29:11.112000: I training.py:186] Saved checkpoint run/ckpt-9000\n",
            "2021-06-20 17:32:48.604000: I runner.py:281] Step = 9100 ; steps/s = 0.46, source words/s = 11277, target words/s = 11235 ; Learning rate = 0.000927 ; Loss = 1.605417\n",
            "2021-06-20 17:36:25.412000: I runner.py:281] Step = 9200 ; steps/s = 0.46, source words/s = 11321, target words/s = 11266 ; Learning rate = 0.000921 ; Loss = 1.591030\n",
            "2021-06-20 17:40:01.150000: I runner.py:281] Step = 9300 ; steps/s = 0.46, source words/s = 11365, target words/s = 11327 ; Learning rate = 0.000916 ; Loss = 1.581678\n",
            "2021-06-20 17:43:36.951000: I runner.py:281] Step = 9400 ; steps/s = 0.46, source words/s = 11373, target words/s = 11319 ; Learning rate = 0.000912 ; Loss = 1.581403\n",
            "2021-06-20 17:47:13.684000: I runner.py:281] Step = 9500 ; steps/s = 0.46, source words/s = 11319, target words/s = 11271 ; Learning rate = 0.000907 ; Loss = 1.582307\n",
            "2021-06-20 17:50:50.213000: I runner.py:281] Step = 9600 ; steps/s = 0.46, source words/s = 11324, target words/s = 11288 ; Learning rate = 0.000902 ; Loss = 1.574019\n",
            "2021-06-20 17:54:26.569000: I runner.py:281] Step = 9700 ; steps/s = 0.46, source words/s = 11340, target words/s = 11289 ; Learning rate = 0.000897 ; Loss = 1.576506\n",
            "2021-06-20 17:58:03.284000: I runner.py:281] Step = 9800 ; steps/s = 0.46, source words/s = 11320, target words/s = 11275 ; Learning rate = 0.000893 ; Loss = 1.576844\n",
            "2021-06-20 18:01:39.787000: I runner.py:281] Step = 9900 ; steps/s = 0.46, source words/s = 11326, target words/s = 11290 ; Learning rate = 0.000888 ; Loss = 1.584904\n",
            "2021-06-20 18:05:16.513000: I runner.py:281] Step = 10000 ; steps/s = 0.46, source words/s = 11321, target words/s = 11271 ; Learning rate = 0.000884 ; Loss = 1.578888\n",
            "2021-06-20 18:05:22.237000: I training.py:186] Saved checkpoint run/ckpt-10000\n",
            "2021-06-20 18:05:22.238000: I training.py:202] Running evaluation for step 10000\n",
            "2021-06-20 18:06:44.254000: I training.py:202] Evaluation predictions saved to run/eval/predictions.txt.10000\n",
            "2021-06-20 18:06:44.254000: I training.py:202] Evaluation result for step 10000: loss = 3.398116 ; perplexity = 29.907703\n",
            "2021-06-20 18:10:20.815000: I runner.py:281] Step = 10100 ; steps/s = 0.46, source words/s = 11323, target words/s = 11284 ; Learning rate = 0.000879 ; Loss = 1.578570\n",
            "2021-06-20 18:13:57.364000: I runner.py:281] Step = 10200 ; steps/s = 0.46, source words/s = 11330, target words/s = 11280 ; Learning rate = 0.000875 ; Loss = 1.591787\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt-main\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/opennmt/bin/main.py\", line 326, in main\n",
            "    hvd=hvd,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/opennmt/runner.py\", line 281, in train\n",
            "    moving_average_decay=train_config.get(\"moving_average_decay\"),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/opennmt/training.py\", line 123, in __call__\n",
            "    dataset, accum_steps=accum_steps, report_steps=report_steps\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/opennmt/training.py\", line 260, in _steps\n",
            "    loss = forward_fn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 917, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3024, in __call__\n",
            "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1961, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 596, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85V1dSiGXVgO"
      },
      "source": [
        "Translate the test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYjF_qcOXV8b",
        "outputId": "eda35c3c-3711-4f21-d2cb-2b10f31287c4"
      },
      "source": [
        "!onmt-main --config Europarl/config.yml --auto_config infer --features_file Europarl/fre_test.txt --predictions_file Europarl/predictions.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-20 18:20:29.923426: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-20 18:20:31.448578: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-06-20 18:20:31.454904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 18:20:31.455846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-06-20 18:20:31.455894: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-20 18:20:31.458727: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-06-20 18:20:31.458796: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-06-20 18:20:31.460474: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-20 18:20:31.460857: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-20 18:20:31.462851: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-20 18:20:31.463572: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-06-20 18:20:31.463766: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-06-20 18:20:31.463861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 18:20:31.464790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 18:20:31.465665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-06-20 18:20:31.468000: I main.py:311] Loading model description from run/model_description.py\n",
            "2021-06-20 18:20:31.604000: I main.py:318] Using OpenNMT-tf version 2.20.0\n",
            "2021-06-20 18:20:31.604000: I main.py:318] Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "2021-06-20 18:20:31.612000: I main.py:340] Using parameters:\n",
            "data:\n",
            "  eval_features_file: Europarl/fre_val.txt\n",
            "  eval_labels_file: Europarl/eng_val.txt\n",
            "  source_vocabulary: Europarl/fre_vocab.txt\n",
            "  target_vocabulary: Europarl/eng_vocab.txt\n",
            "  train_features_file: Europarl/fre_train.txt\n",
            "  train_labels_file: Europarl/eng_train.txt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  early_stopping:\n",
            "    metric: loss\n",
            "    min_improvement: 0.05\n",
            "    steps: 4\n",
            "  length_bucket_width: 5\n",
            "  save_eval_predictions: true\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: run/\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 2.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: LazyAdam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.9\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 1\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 100\n",
            "  maximum_labels_length: 100\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "2021-06-20 18:20:31.919651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 18:20:31.920459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-06-20 18:20:31.920549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 18:20:31.921391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 18:20:31.922072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-06-20 18:20:31.922141: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-20 18:20:32.542152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-20 18:20:32.542218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-06-20 18:20:32.542255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-06-20 18:20:32.542433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 18:20:32.543432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 18:20:32.544282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-20 18:20:32.545152: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-06-20 18:20:32.545239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15088 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2021-06-20 18:20:32.733000: I runner.py:419] Restored checkpoint run/ckpt-10000\n",
            "2021-06-20 18:20:33.794000: I runner.py:433] Tracing and optimizing the inference graph...\n",
            "2021-06-20 18:20:43.822000: W deprecation.py:534] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "2021-06-20 18:20:50.620040: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-06-20 18:20:50.620638: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2299995000 Hz\n",
            "2021-06-20 18:20:51.891719: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 18:20:51.893434: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 18:20:51.895122: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 18:20:51.897156: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 18:20:51.898839: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 18:20:51.900483: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 18:20:51.920759: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 18:20:51.923216: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 18:20:51.925301: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 18:20:51.927467: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 18:20:51.929875: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 18:20:51.932113: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8004\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 15821701120 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
            "2021-06-20 18:20:52.719897: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-06-20 18:20:53.010288: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8004\n",
            "2021-06-20 18:20:53.045265: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-06-20 18:20:53.303499: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-06-20 18:21:06.926000: I runner.py:433] 1340 predictions are buffered, but waiting for the prediction of line 6 to advance the output...\n",
            "2021-06-20 18:21:17.166000: I runner.py:433] 2300 predictions are buffered, but waiting for the prediction of line 6 to advance the output...\n",
            "2021-06-20 18:21:30.324000: I runner.py:433] 3405 predictions are buffered, but waiting for the prediction of line 53 to advance the output...\n",
            "2021-06-20 18:21:42.672000: I runner.py:433] 4406 predictions are buffered, but waiting for the prediction of line 172 to advance the output...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06YTrcKRsOOj"
      },
      "source": [
        "Create function to load functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuHJ5amb8Ugo"
      },
      "source": [
        "def load_doc(filename):\n",
        "    # open the file as read only\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "    # read all text\n",
        "    text = file.read()\n",
        "    # close the file\n",
        "    file.close()\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODlCtSNKsaeh"
      },
      "source": [
        "Calculate BLEU score for the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QkPsZk36lYC",
        "outputId": "f5766a76-5653-4d4e-e2af-62712d3e6394"
      },
      "source": [
        "import sacrebleu\n",
        "sys = load_doc(\"Europarl/predictions.txt\")\n",
        "ref = load_doc(\"Europarl/eng_test.txt\")\n",
        "\n",
        "bleu = sacrebleu.corpus_bleu(sys, ref)\n",
        "print(bleu.score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41.189843624714385\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}